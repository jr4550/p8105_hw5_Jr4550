p8105_hw5_JR4550
================
Jeff Remo
2025-11-15

## set up environment

``` r
library(tidyverse)
library(rvest)
library(broom)
library(purrr)
```

## Problem 2

Create function

``` r
set.seed(1)

sim_t_test = function(n = 30, mu, sigma = 5) {
  x = rnorm(n, mean = mu, sd = sigma)
    test_result = t.test(x, mu = 0) %>%
    tidy() %>%
    select(estimate, p.value)
  
  test_result
}
```

#### Simulation for mu

``` r
sim_results_all = 
  tibble(
    true_mu = c(0:6)
  ) %>%
  mutate(
    results = map(true_mu, ~rerun(5000, sim_t_test(mu = .x)))
  ) %>%
  unnest(results) %>%
  mutate(
    iteration = rep(1:5000, times = 7)
  ) %>%
  unnest(results)
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ‚Ñπ In argument: `results = map(true_mu, ~rerun(5000, sim_t_test(mu = .x)))`.
    ## Caused by warning:
    ## ! `rerun()` was deprecated in purrr 1.0.0.
    ## ‚Ñπ Please use `map()` instead.
    ##   # Previously
    ##   rerun(5000, sim_t_test(mu = .x))
    ## 
    ##   # Now
    ##   map(1:5000, ~ sim_t_test(mu = .x))

``` r
power_results = 
  sim_results_all %>%
  group_by(true_mu) %>%
  summarize(
    power = mean(p.value < 0.05)
  )
```

#### Plot 1 Power Results

``` r
power_results %>%
  ggplot(aes(x = true_mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Power of One-Sample t-Test vs Effect Size",
    x = "True Value of Œº",
    y = "Power (Proportion of Times Null Rejected)"
  ) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1))
```

![](p8105_hw5_jr4550_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

``` r
avg_estimates = 
  sim_results_all %>%
  group_by(true_mu) %>%
  summarize(
    avg_estimate_all = mean(estimate),
    avg_estimate_rejected = mean(estimate[p.value < 0.05])
  )
```

#### Association of Size and Power:

The plot shows a strong positive link between effect size and power.
When Œº = 0 (no effect), power is about 0.05, the same as Œ± (the Type I
error rate). As the effect size gets bigger, power goes up quickly. When
Œº = 4, power is close to 1, so we almost always find the true effect.
This means it‚Äôs easier to spot larger effect sizes with the same sample
size and variance.

#### Plot 2 All samples

``` r
p1 = avg_estimates %>%
  ggplot(aes(x = true_mu, y = avg_estimate_all)) +
  geom_line() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  labs(
    title = "Average Estimate of ŒºÃÇ (All Samples)",
    x = "True Value of Œº",
    y = "Average Estimate of ŒºÃÇ"
  ) +
  theme_minimal()
```

# Plot 3: Rejected null only

``` r
p2 = avg_estimates %>%
  ggplot(aes(x = true_mu, y = avg_estimate_rejected)) +
  geom_line() +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  labs(
    title = "Average Estimate of ŒºÃÇ (Rejected Null Only)",
    x = "True Value of Œº",
    y = "Average Estimate of ŒºÃÇ"
  ) +
  theme_minimal()
```

``` r
library(patchwork)
p1 / p2
```

![](p8105_hw5_jr4550_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->

``` r
print("Power by True Œº:")
```

    ## [1] "Power by True Œº:"

``` r
print(power_results)
```

    ## # A tibble: 7 √ó 2
    ##   true_mu  power
    ##     <int>  <dbl>
    ## 1       0 0.0508
    ## 2       1 0.189 
    ## 3       2 0.568 
    ## 4       3 0.887 
    ## 5       4 0.992 
    ## 6       5 1     
    ## 7       6 1

``` r
print("\nAverage Estimates:")
```

    ## [1] "\nAverage Estimates:"

``` r
print(avg_estimates)
```

    ## # A tibble: 7 √ó 3
    ##   true_mu avg_estimate_all avg_estimate_rejected
    ##     <int>            <dbl>                 <dbl>
    ## 1       0        -0.000262                0.0426
    ## 2       1         0.996                   2.21  
    ## 3       2         2.00                    2.60  
    ## 4       3         2.99                    3.18  
    ## 5       4         3.99                    4.01  
    ## 6       5         5.01                    5.01  
    ## 7       6         6.02                    6.02

#### Is the sample average of ùúáÃÇ across tests for which the null is rejected approximately equal to the true value of ùúá? Why or why not?

No, not always. When considering all samples, the average estimate
equals the true Œº because ŒºÃÇ is unbiased. However, among only the samples
where the null was rejected, the average estimate is larger than the
true Œº for small effect sizes. This happens because when power is low,
we only reject the null when we get unusually large sample estimates,
creating selection bias. As the true effect size increases and power
approaches 1, this bias disappears because we reject the null in nearly
all samples.

#### Problem 3
